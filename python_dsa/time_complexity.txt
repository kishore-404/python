# âœ… Definition:
# Time Complexity is a way to measure how the **runtime of an algorithm grows** 
# with the size of the input (denoted as 'n').
# It is expressed using **Big O notation**.

# âœ… Why we need Time Complexity:
# ğŸ”¹ To compare the **efficiency** of algorithms
# ğŸ”¹ To avoid writing **slow code** for large inputs
# ğŸ”¹ To prepare for coding interviews and system design
# ğŸ”¹ Helps make better **performance decisions**

# -------------------------------------------------------

# âœ… Common Big O Time Complexities:

# ğŸ”¸ O(1) â€” Constant time
#     Always takes the same amount of time regardless of input size
# ğŸ”¸ O(log n) â€” Logarithmic time
#     Input size is divided each time (e.g., binary search)
# ğŸ”¸ O(n) â€” Linear time
#     Time increases proportionally with input size
# ğŸ”¸ O(n log n) â€” Linearithmic time
#     Common in efficient sorting algorithms (Merge Sort, Quick Sort)
# ğŸ”¸ O(nÂ²) â€” Quadratic time
#     Often found in nested loops (Bubble Sort, brute-force algorithms)
# ğŸ”¸ O(2â¿), O(n!) â€” Exponential & Factorial time
#     Extremely slow; used in complex recursive problems (like backtracking)

# -------------------------------------------------------

# âœ… Example 1: Constant Time - O(1)

def get_first_element(lst):
    return lst[0]

# No matter the size of lst, it takes 1 step

# -------------------------------------------------------

# âœ… Example 2: Linear Time - O(n)

def print_all(lst):
    for item in lst:
        print(item)

# As the input size grows, the loop runs more times

# -------------------------------------------------------

# âœ… Example 3: Quadratic Time - O(nÂ²)

def print_pairs(lst):
    for i in lst:
        for j in lst:
            print(i, j)

# Two nested loops over the same list â†’ n * n = nÂ²

# -------------------------------------------------------

# âœ… Visualization (for intuition):
# Input size n = 5
# O(1) â†’ 1 step
# O(n) â†’ 5 steps
# O(nÂ²) â†’ 25 steps
# O(2â¿) â†’ 32 steps

# -------------------------------------------------------

# âœ… Time Complexity vs. Space Complexity:

# Time Complexity â†’ How long it takes to run
# Space Complexity â†’ How much memory it uses

# Often a trade-off: faster algorithms may use more memory and vice versa.

# -------------------------------------------------------

# âœ… How to calculate time complexity:
# ğŸ”¹ Count number of basic operations (in worst-case scenario)
# ğŸ”¹ Focus on loops, recursion, nested calls
# ğŸ”¹ Drop constants and less significant terms (e.g., O(3n + 5) â†’ O(n))

# -------------------------------------------------------

# âœ… Benefits of analyzing time complexity:
# ğŸ”¸ Predict performance before running the code
# ğŸ”¸ Improve scalability for large datasets
# ğŸ”¸ Compare algorithms meaningfully

# -------------------------------------------------------

# âœ… Limitations:
# âŒ Does not measure actual execution time
# âŒ Assumes worst-case unless stated otherwise
# âŒ Doesn't consider real-world factors like hardware, caching, etc.

